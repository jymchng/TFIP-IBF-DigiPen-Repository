{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier():\n",
    "    '''\n",
    "    Bayes Theorem form\n",
    "    P(y|X) = P(X|y) * P(y) / P(X)\n",
    "    '''\n",
    "    def calc_prior(self, features, target):\n",
    "        '''\n",
    "        prior probability P(y)\n",
    "        calculate prior probabilities\n",
    "        '''\n",
    "        self.prior = (features.groupby(target).apply(lambda x: len(x)) / self.rows).to_numpy()\n",
    "\n",
    "        return self.prior\n",
    "    \n",
    "    def calc_statistics(self, features, target):\n",
    "        '''\n",
    "        calculate mean, variance for each column and convert to numpy array\n",
    "        ''' \n",
    "        self.mean = features.groupby(target).apply(np.mean).to_numpy()\n",
    "        self.var = features.groupby(target).apply(np.var).to_numpy()\n",
    "              \n",
    "        return self.mean, self.var\n",
    "    \n",
    "    def gaussian_density(self, class_idx, x):     \n",
    "        '''\n",
    "        calculate probability from gaussian density function (normally distributed)\n",
    "        we will assume that probability of specific target value given specific class is normally distributed \n",
    "        \n",
    "        probability density function derived from wikipedia:\n",
    "        (1/√2pi*σ) * exp((-1/2)*((x-μ)^2)/(2*σ²)), where μ is mean, σ² is variance, σ is quare root of variance (standard deviation)\n",
    "        '''\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        numerator = np.exp((-1/2)*((x-mean)**2) / (2 * var))\n",
    "#         numerator = np.exp(-((x-mean)**2 / (2 * var)))\n",
    "        denominator = np.sqrt(2 * np.pi * var)\n",
    "        prob = numerator / denominator\n",
    "        return prob\n",
    "    \n",
    "    def calc_posterior(self, x):\n",
    "        posteriors = []\n",
    "\n",
    "        # calculate posterior probability for each class\n",
    "        for i in range(self.count):\n",
    "            prior = np.log(self.prior[i]) ## use the log to make it more numerically stable\n",
    "            conditional = np.sum(np.log(self.gaussian_density(i, x))) # use the log to make it more numerically stable\n",
    "            posterior = prior + conditional\n",
    "            posteriors.append(posterior)\n",
    "        # return class with highest posterior probability\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "     \n",
    "\n",
    "    def fit(self, features, target):\n",
    "        self.classes = np.unique(target)\n",
    "        self.count = len(self.classes)\n",
    "        self.feature_nums = features.shape[1]\n",
    "        self.rows = features.shape[0]\n",
    "        \n",
    "        self.calc_statistics(features, target)\n",
    "        self.calc_prior(features, target)\n",
    "        \n",
    "    def predict(self, features):\n",
    "        preds = [self.calc_posterior(f) for f in features.to_numpy()]\n",
    "        return preds\n",
    "\n",
    "    def accuracy(self, y_test, y_pred):\n",
    "        accuracy = np.sum(y_test == y_pred) / len(y_test)\n",
    "        return accuracy\n",
    "\n",
    "    def visualize(self, y_true, y_pred, target):\n",
    "        \n",
    "        tr = pd.DataFrame(data=y_true, columns=[target])\n",
    "        pr = pd.DataFrame(data=y_pred, columns=[target])\n",
    "        \n",
    "        \n",
    "        fig, ax = plt.subplots(1, 2, sharex='col', sharey='row', figsize=(15,6))\n",
    "        \n",
    "        sns.countplot(x=target, data=tr, ax=ax[0], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        sns.countplot(x=target, data=pr, ax=ax[1], palette='viridis', alpha=0.7, hue=target, dodge=False)\n",
    "        \n",
    "\n",
    "        fig.suptitle('True vs Predicted Comparison', fontsize=20)\n",
    "\n",
    "        ax[0].tick_params(labelsize=12)\n",
    "        ax[1].tick_params(labelsize=12)\n",
    "        ax[0].set_title(\"True values\", fontsize=18)\n",
    "        ax[1].set_title(\"Predicted values\", fontsize=18)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
