{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking and Removal of Missing Data\n",
    "\n",
    "Real-world data often has missing values. Data can have missing values for a number of reasons such as observations that were not recorded and data corruption. Handling missing data is important as many machine learning algorithms do not support data with missing values. In this exercise, you will discover how to handle missing data for machine learning with Python.\n",
    "\n",
    "Specifically, after completing this exercise you will know:\n",
    "- How to mark invalid or corrupt values as missing in your dataset.\n",
    "- How to confirm that the presence of marked missing values causes problems for learning algorithms.\n",
    "- How to remove rows with missing data from your dataset and evaluate a learning algorithm on the transformed dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Exercise Overview\n",
    "\n",
    "This exercise is divided into 4 parts; they are:\n",
    "1. Diabetes Dataset\n",
    "2. Mark Missing Values\n",
    "3. Missing Values Cause Problems\n",
    "4. Remove Rows With Missing Values\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Diabetes Dataset\n",
    "\n",
    "As the basis of this exercise, we will use the *diabetes* dataset. The dataset classifies patient data as either an onset of diabetes within five years or not. There are 768 examples and eight input variables. It is a binary classification problem. A naive model can achieve an accuracy of about 65 percent on this dataset. A good score is about 77 percent. We will aim for this region, but note that the models in this tutorial are not optimized; they are designed to demonstrate feature selection schemes.\n",
    "\n",
    "Looking at the data, we can see that all nine input variables are numerical.\n",
    "\n",
    "```\n",
    "6,148,72,35,0,33.6,0.627,50,1\n",
    "1,85,66,29,0,26.6,0.351,31,0\n",
    "8,183,64,0,0,23.3,0.672,32,1\n",
    "1,89,66,23,94,28.1,0.167,21,0\n",
    "0,137,40,35,168,43.1,2.288,33,1\n",
    "...\n",
    "```\n",
    "\n",
    "This dataset is known to have missing values. Specifically, there are missing observations for\n",
    "some columns that are marked as a zero value. We can corroborate this by the definition of\n",
    "those columns and the domain knowledge that a zero value is invalid for those measures, e.g. a\n",
    "zero for body mass index or blood pressure is invalid.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Mark Missing Values\n",
    "\n",
    "Most data has missing values, and the likelihood of having missing values increases with the\n",
    "size of the dataset. Missing data are not rare in real data sets. In fact, the chance that at least one data point is missing increases as the data set size increases. In this section, we will look at how we can identify and mark values as missing.\n",
    "\n",
    "- Use the `describe()` function to help identify missing or corrupt data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is useful. We can see that there are columns that have a minimum value of zero (0).\n",
    "On some columns, a value of zero does not make sense and indicates an invalid or missing value.\n",
    "\n",
    "Specifically, the following columns must have an invalid zero minimum value:\n",
    "1. Plasma glucose concentration\n",
    "2. Diastolic blood pressure\n",
    "3. Triceps skinfold thickness\n",
    "4. 2-Hour serum insulin\n",
    "5. Body mass index\n",
    "\n",
    "- Confirm this by looking at the first 20 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that there 0 values in the columns 2, 3, 4, and 5.\n",
    "\n",
    "\n",
    "We can get a count of the number of missing values on each of these columns. We can do this by marking all of the values in the subset of the dataframe we are interested in that have zero values as True.\n",
    "\n",
    "- Count the number of true values in each column.\n",
    "  \n",
    "  Expected output:\n",
    "  ```\n",
    "  1 5\n",
    "  2 35\n",
    "  3 227\n",
    "  4 374\n",
    "  5 11\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that columns 1, 2 and 5 have just a few zero values, whereas columns 3 and 4 show a lot more, nearly half of the rows. This highlights that different missing value strategies may be needed for different columns, e.g. to ensure that there are still a sufficient number of records left to train a predictive model.\n",
    "\n",
    "In Python, specifically Pandas, NumPy and Scikit-Learn, we mark missing values as NaN (Not a Number). Values with a NaN value are ignored from operations like sum, count, etc.\n",
    "\n",
    "- Mark and replace values as NaN with the `Pandas DataFrame` by using the `replace()` function on a subset of the columns we are interested in. You may need to import the `nan` from Numpy. Confirm your new dataset by looking at the first 20 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After marking the missing values, use the `isnull()` function to mark all of the NaN values in the dataset as `True` and count of the missing values for each column.\n",
    "\n",
    "  Expected output:\n",
    "  ```\n",
    "  0      0\n",
    "  1      5\n",
    "  2     35\n",
    "  3    227\n",
    "  4    374\n",
    "  5     11\n",
    "  6      0\n",
    "  7      0\n",
    "  8      0\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at handling missing values, let's first demonstrate that having missing values\n",
    "in a dataset can cause problems.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Missing Values Cause Problems\n",
    "\n",
    "Having missing values in a dataset can cause errors with some machine learning algorithms. Missing values are common occurrences in data. Unfortunately, most predictive modeling techniques cannot handle any missing values. Therefore, this problem must be addressed prior to modeling.\n",
    "\n",
    "In this section, we will try to evaluate the *Linear Discriminant Analysis* (LDA) algorithm\n",
    "on the dataset with missing values. While you have not learnt this, LDA is an algorithm that does not work when there are missing values in the dataset.\n",
    "\n",
    "The example below marks the missing values in the dataset, as we did in the previous section, then attempts to evaluate LDA using 3-fold cross-validation and print the mean accuracy.\n",
    "\n",
    "- Try running the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example where missing values cause errors\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# split dataset into inputs and outputs\n",
    "values = dataset.values\n",
    "X = values[:,0:8]\n",
    "y = values[:,8]\n",
    "# define the model\n",
    "model = LinearDiscriminantAnalysis()\n",
    "# define the model evaluation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# evaluate the model\n",
    "result = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
    "# report the mean performance\n",
    "print('Accuracy: %.3f' % result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are prevented from evaluating an LDA algorithm (and other algorithms) on the dataset with missing values. Many popular predictive models such as support vector machines, the glmnet, and neural networks, cannot tolerate any amount of missing values.\n",
    "\n",
    "Now, we can look at methods to handle the missing values.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Remove Rows With Missing Values\n",
    "\n",
    "The simplest strategy for handling missing data is to remove records that contain a missing\n",
    "value.\n",
    "\n",
    "We can do this by creating a new Pandas `DataFrame` with the rows containing missing values removed. Pandas provides the `dropna()` function that can be used to drop either columns or rows with missing data. \n",
    "\n",
    "- Complete the following code snippet using `dropna()` to remove all rows with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of removing rows that contain missing values\n",
    "from numpy import nan\n",
    "from pandas import read_csv\n",
    "# load the dataset\n",
    "dataset = read_csv('pima-indians-diabetes.csv', header=None)\n",
    "# summarize the shape of the raw data\n",
    "print(dataset.shape)\n",
    "# replace '0' values with 'nan'\n",
    "dataset[[1,2,3,4,5]] = dataset[[1,2,3,4,5]].replace(0, nan)\n",
    "# drop rows with missing values (Write your code here)\n",
    "\n",
    "# summarize the shape of the data with missing rows removed\n",
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should expect that the number of rows to be aggressively cut from 768 in the original dataset to 392 after all the rows containing NaN have been removed.\n",
    "\n",
    "- Using the new dataset, re-evaluate the LDA algorithm (Answer: Accuracy 0.781)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, removing rows with missing values can be too limiting on some predictive modeling problems. An alternative is to impute missing values. We will explore how we can impute missing data values using statistics later.\n",
    "\n",
    "---\n",
    "\n",
    "7. Summary\n",
    "\n",
    "In this exercise, you discovered how to handle machine learning data that contains missing\n",
    "values. Specifically, you learned:\n",
    "- How to mark invalid or corrupt values as missing in your dataset.\n",
    "- How to confirm that the presence of marked missing values causes problems for learning algorithms.\n",
    "- How to remove rows with missing data from your dataset and evaluate a learning algorithm on the transformed dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
