{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GMM vs Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by creating a synthetic dataset for this task. To make it more challenging, we will create 2 overlapping Gaussian distributions and add a uniform distribution on the side.\n",
    "* Kmeans\n",
    "* GMM\n",
    "* GMM with Kmeans initializer\n",
    "* Computation Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from numpy.random import multivariate_normal\n",
    "from numpy.random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(n_samples=3000):\n",
    "  \"\"\" Create dataset with 2 Gaussian distributions and uniform distribution\"\"\"\n",
    "  n_sample = n_samples//3\n",
    "  data = np.zeros([n_samples, 3])\n",
    "\n",
    "  data_0 = multivariate_normal(mean=[-1, 1], cov=[[2, 1],[1, 2]], size=(n_sample))\n",
    "  data_1 = multivariate_normal(mean=[1, 5], cov=[[3, 1],[2, 1]], size=(n_sample))\n",
    "  data_2 = uniform([5, -3], [10, 5], size=(n_sample, 2))\n",
    "\n",
    "  # Merged all datapoints into one dataset\n",
    "  data[:n_sample, :2] = data_0\n",
    "  data[:n_sample, 2] = np.asarray([0]*n_sample)\n",
    "  data[n_sample:2*n_sample, :2] = data_1\n",
    "  data[n_sample:2*n_sample, 2] = np.asarray([1]*n_sample)\n",
    "  data[2*n_sample:, :2] = data_2\n",
    "  data[2*n_sample:, 2] = np.asarray([2]*n_sample)\n",
    "\n",
    "  return data\n",
    "\n",
    "\n",
    "def plot_dataset(data):\n",
    "  \"\"\" Plots the generated dataset\"\"\"\n",
    "  data_0 = data[data[:, 2] == 0][:, :2]\n",
    "  data_1 = data[data[:, 2] == 1][:, :2]\n",
    "  data_2 = data[data[:, 2] == 2][:, :2]\n",
    "\n",
    "  plt.scatter(data_0[:, 0], data_0[:, 1], c='r', label=\"Cluster 1\")\n",
    "  plt.scatter(data_1[:, 0], data_1[:, 1], c='b', label=\"Cluster 2\")\n",
    "  plt.scatter(data_2[:, 0], data_2[:, 1], c='g', label=\"Cluster 3\")\n",
    "  plt.legend()\n",
    "  plt.title(\"2 ovelapping Gaussian distributions and one uniform distribution\")\n",
    "  plt.show()\n",
    "  plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_dataset()\n",
    "plot_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Initialize KMeans and GaussianMixture models\n",
    "kmeans = KMeans(n_clusters=3, \n",
    "                max_iter=1000,\n",
    "                tol=1e-4)\n",
    "gm = GaussianMixture(n_components=3, \n",
    "                     max_iter=1000, \n",
    "                     tol=1e-4,\n",
    "                     init_params='random')\n",
    "\n",
    "# Fit and predict the algorithms\n",
    "y_kmeans = kmeans.fit_predict(data[:, :2])\n",
    "y_gm = gm.fit_predict(data[:, :2])\n",
    "y_gm_proba = gm.predict_proba(data[:, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \"\"\"Plot the results in one figure\"\"\"\n",
    "  fig, ax = plt.subplots(1, 3)\n",
    "  fig.set_size_inches(20, 8, forward=True)  \n",
    "  labels = [data[:, 2], y_kmeans, y_gm]\n",
    "  title = [\"True labels\", \"KMeans\", \"GMs\"]\n",
    "\n",
    "  for i in range(len(labels)):\n",
    "    data_0 = data[labels[i] == 0][:, :2]\n",
    "    data_1 = data[labels[i] == 1][:, :2]\n",
    "    data_2 = data[labels[i] == 2][:, :2]\n",
    "    ax[i].scatter(data_0[:, 0], data_0[:, 1], c='r', label=\"Cluster 1\")\n",
    "    ax[i].scatter(data_1[:, 0], data_1[:, 1], c='b', label=\"Cluster 2\")\n",
    "    ax[i].scatter(data_2[:, 0], data_2[:, 1], c='g', label=\"Cluster 3\")\n",
    "    ax[i].set_title(title[i])\n",
    "    ax[i].legend()\n",
    "  \n",
    "  plt.show()\n",
    "\n",
    "plot_results(data, y_kmeans, y_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_different_gms(data, threshold, \n",
    "                       y_gm, y_gm_proba, \n",
    "                       y_gm_kmeans, y_gm_proba_kmeans):\n",
    "  \"\"\" Plots GMs with a random and kmeans initializer\"\"\"\n",
    "  fig, ax = plt.subplots(1, 3)\n",
    "  fig.set_size_inches(20, 8, forward=True)\n",
    "\n",
    "  # Create new label (\"unknown\") for predictions < probability threshold\n",
    "  y_gm_proba = np.amax(y_gm_proba, axis=1)\n",
    "  y_gm[y_gm_proba < threshold] = 3\n",
    "  \n",
    "  y_gm_proba_kmeans = np.amax(y_gm_proba_kmeans, axis=1)\n",
    "  y_gm_kmeans[y_gm_proba_kmeans < threshold] = 3\n",
    "\n",
    "  labels = [data[:, 2], y_gm, y_gm_kmeans]\n",
    "  title = [\"True labels\", \n",
    "           \"GMs with random initializer\", \n",
    "           \"GMs with KMeans as initialization\"]\n",
    "  \n",
    "  for i in range(len(labels)):\n",
    "    data_0 = data[labels[i] == 0][:, :2]\n",
    "    data_1 = data[labels[i] == 1][:, :2]\n",
    "    data_2 = data[labels[i] == 2][:, :2]\n",
    "    ax[i].scatter(data_0[:, 0], data_0[:, 1], c='r', label=\"Cluster 1\")\n",
    "    ax[i].scatter(data_1[:, 0], data_1[:, 1], c='b', label=\"Cluster 2\")\n",
    "    ax[i].scatter(data_2[:, 0], data_2[:, 1], c='g', label=\"Cluster 3\")\n",
    "    \n",
    "    if i != 0:\n",
    "      # First data are just true labels for comparison\n",
    "      data_3 = data[labels[i] == 3][:, :2]\n",
    "      ax[i].scatter(data_3[:, 0], data_3[:, 1], c='black', label=\"Unknown Cluster\")\n",
    "    \n",
    "    ax[i].set_title(title[i])\n",
    "    ax[i].legend()\n",
    "\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm = GaussianMixture(n_components=3, \n",
    "                     max_iter=1000, \n",
    "                     tol=1e-4,\n",
    "                     init_params='random')\n",
    "gm_kmeans = GaussianMixture(n_components=3, \n",
    "                            max_iter=1000, \n",
    "                            tol=1e-4,\n",
    "                            init_params='kmeans')\n",
    "\n",
    "y_gm = gm.fit_predict(data[:, :2])\n",
    "y_gm_proba = gm.predict_proba(data[:, :2])\n",
    "\n",
    "y_gm_kmeans = gm_kmeans.fit_predict(data[:, :2])\n",
    "y_gm_proba_kmeans = gm_kmeans.predict_proba(data[:, :2])\n",
    "\n",
    "plot_different_gms(data, 0.34, \n",
    "                   y_gm, y_gm_proba, \n",
    "                   y_gm_kmeans, y_gm_proba_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measuring Computation Time\n",
    "data_new = create_dataset(12000)\n",
    "# Dictionary to gather the results\n",
    "elapsed_time = {\n",
    "    \"k\": [],\n",
    "    \"gm\": [] ,\n",
    "    \"gm_kmeans\": [],\n",
    "    \"kmeans\": [] \n",
    "}\n",
    "\n",
    "# Measure time for different number of clusters\n",
    "for i in range(1, 11):\n",
    "  kmeans = KMeans(n_clusters=3, \n",
    "                max_iter=1000,\n",
    "                tol=1e-4)\n",
    "  gm = GaussianMixture(n_components=3, \n",
    "                     max_iter=1000, \n",
    "                     tol=1e-4,\n",
    "                     init_params='random')\n",
    "  gm_kmeans = GaussianMixture(n_components=3, \n",
    "                            max_iter=1000, \n",
    "                            tol=1e-4,\n",
    "                            init_params='kmeans')\n",
    "  \n",
    "  start_kmeans = time.time()\n",
    "  kmeans.fit_predict(data_new)\n",
    "  stop_kmeans = time.time()\n",
    "\n",
    "  gm.fit_predict(data_new)\n",
    "  start_gm = time.time()\n",
    "  stop_gm = time.time()\n",
    "  \n",
    "  start_gm_kmeans = time.time()\n",
    "  gm_kmeans.fit_predict(data_new)\n",
    "  stop_gm_kmeans = time.time()\n",
    "\n",
    "  elapsed_time[\"k\"].append(i)\n",
    "  elapsed_time[\"kmeans\"].append(stop_kmeans-start_kmeans)\n",
    "  elapsed_time[\"gm\"].append(stop_gm-start_gm)\n",
    "  elapsed_time[\"gm_kmeans\"].append(stop_gm_kmeans-start_gm_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results from the dictionary\n",
    "plt.plot(elapsed_time[\"k\"], elapsed_time[\"kmeans\"], label=\"kmeans\")\n",
    "plt.plot(elapsed_time[\"k\"], elapsed_time[\"gm\"], label=\"gm\")\n",
    "plt.plot(elapsed_time[\"k\"], elapsed_time[\"gm_kmeans\"], label=\"gm_kmeans\")\n",
    "plt.legend()\n",
    "plt.title(\"Elapsed time for different number of clusters\")\n",
    "plt.xlabel(\"Number of clusters K\")\n",
    "plt.ylabel(\"Time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
